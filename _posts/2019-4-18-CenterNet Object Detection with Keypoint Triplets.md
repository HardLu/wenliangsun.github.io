---
layout: post
title: "论文笔记：CenterNet: Object Detection with Keypoint Triplets"
subtitle: 'Object Detection'
author: "WenlSun"
header-style: text
tags:
  - Object Detection
---

### 引言

传统的基于关键点的目标检测方法例如最具代表性的 CornerNet [1] 通过检测物体的左上角点和右下角点来确定目标，但在确定目标的过程中，无法有效利用物体的内部的特征，即无法感知物体内部的信息，从而导致该类方法产生了很多误检 (错误目标框)。本文利用关键点三元组即中心点、左上角点和右下角点三个关键点而不是两个点来确定一个目标，使网络花费了很小的代价便具备了感知物体内部信息的能力，从而能有效抑制误检。另外，为了更好的检测中心点和角点，我们分别提出了 center pooling 和 cascade corner pooling 来提取中心点和角点的特征。我们方法的名字叫 CenterNet，是一种 one-stage 的方法，在最具挑战性之一的数据集 MS COCO [2] 上，获得了47% AP，超过了所有已知的 one-stage 检测方 法，并大幅度领先，其领先幅度至少达 4.9%。


### CenterNet 原理

我们抑制误检的原理基于以下推论：如果目标框是准确的，那么在其中心区域能够检测到目标中心点的概率就会很高，反之亦然。因此，首先利用左上和右下两个角点生成初始目标框，对每个预测框定义一个中心区域，然后判断每个目标框的中心区域是否含有中心点，若有则保留该目标框，若无则删除该目标框，其原理如图1所。

![1555580821310](img/post-CenterNet-fig1a.png)

### **Baseline 和 Motivation**

其实不光是基于关键点的 one-stage 方法无法感知物体内部信息，几乎所有的 one-stage 方法都存在这一问题。本论文的 baseline 为 CornerNet，因此首先讨论 CornerNet 为什么容易产生很多的误检。首先，CornerNet 通过检测角点确定目标，而不是通过初始候选框 anchor 的回归确定目标，由于没有了 anchor 的限制，使得任意两个角点都可以组成一个目标框，这就对判断两个角点是否属于同一物体的算法要求很高，一但准确度差一点，就会产生很多错误目标框。其次，恰恰这个算法有缺陷。因为此算法在判断两个角点是否属于同一物体时，缺乏全局信息的辅助，因此很容易把原本不是同一物体的两个角点看成是一对角点，因此产生了很多错误目标框。最后，角点的特征对边缘比较敏感，这导致很多角点同样对背景的边缘很敏感，因此在背景处也检测到了错误的角点。综上原因，使得 CornerNet 产生了很多误检。如图2所示，我们用 CornerNet 对两张图片进行检测，根据每个预测目标框的 confidence 选出 top100 个预测框 (根据 MS COCO 标准)，可以发现产生了很多误检。其中蓝色框为 ground truth, 红色框为预测框。

![1555580911080](img/post-CenterNet-fig1b.png)

为了能够量化的分析误检问题，我们提出了一种新的衡量指标，称为FD (false discovery) rate, 此指标能够很直观的反映出误检情况。FD rate 的计算方式为 FD = 1-AP， 其中 AP 为 IoU 阈值取[0.05 : 0.05 : 0.5]下的平均精度。我们统计了 CornerNet 的误检情况，如表1所示:

![1555580977487](img/post-CenterNet-tb1.png)

可以看到，*FD* = 37.8，而 *FD5*高达32.7，这意味着即使我们把条件限制的很严格：只有那些与 ground-truth 的 IoU< 0.05 的才被认定为错误目标框，每100个预测框中仍然平均有32.7 个错误目标框！而小尺度的目标框其FD更是达到了60.3！

我们分析出了 CornerNet 的问题后，接下来就是找出解决之道，关键问题在于让网络具备感知物体内部信息的能力。一个较容易想到的方法是把 CornerNet 变成一个 two-stage 的方法，即利用 RoI pooling 或 RoI align 提取预测框的内部信息，从而获得感知能力。但这样做开销很大，因此我们提出了用关键点三元组来检测目标，这样使得我们的方法在 one-stage 的前提下就能获得感知物体内部信息的能力。并且开销较小，因为我们只需关注物体的中心，从而避免了 RoI pooling 或 RoI align 关注物体内部的全部信息。



### 方法介绍

#### 1.利用关键点三元组检测物体

![1555581226452](img/post-CenterNet-fig2.png)

图3为 CenterNet 的结构图。网络通过 center pooling 和 cascade corner pooling 分别得到 center heatmap 和 corner heatmaps，用来预测关键点的位置。得到角点的位置和类别后，通过 offsets 将角点的位置映射到输入图片的对应位置，然后通过 embedings 判断哪两个角点属于同一个物体，以便组成一个检测框。正如前文所说，组合过程中由于缺乏来自目标区域内部信息的辅助，从而导致大量的误检。为了解决这一问题，CenterNet 不仅预测角点，还预测中心点。我们对每个预测框定义一个中心区域，通过判断每个目标框的中心区域是否含有中心点，若有则保留，并且此时框的 confidence 为中心点，左上角点和右下角点的confidence的平均，若无则去除，使得网络具备感知目标区域内部信息的能力，能够有效除错误的目标框。

我们发现中心区域的尺度会影响错误框去除效果。中心区域过小导致很多小尺度的错误目标框无法被去除，而中心区域过大导致很多大尺度的错误目标框无法被去除，因此我们提出了尺度可调节的中心区域定义法 (公式1)。该方法可以在预测框的尺度较大时定义一个相对较小的中心区域，在预测框的尺度较小时预测一个相对较大的中心区域。如 Fig3 所示。

![1555581328460](img/post-CenterNet-fm1.png)

![1555581386316](img/post-CenterNet-fig3.png)

